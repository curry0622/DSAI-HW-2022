# -*- coding: utf-8 -*-
"""Time Series Prediction with LSTM Using PyTorch

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1l-N6l0-j9ab83Esia5M1KWwHkkY-LNM0

## Library
"""

import csv
import numpy as np
import pandas as pd
import torch
import torch.nn as nn
from torch.autograd import Variable
from sklearn.preprocessing import MinMaxScaler
from datetime import datetime as dt
from matplotlib import pyplot as plt, dates as mdates

def train_and_predict(input_file_name, output_file_name):
  """## Data Explore"""

  training_set = pd.read_csv(input_file_name)
  training_set.head()

  """## Data Plot"""

  training_set = pd.read_csv(input_file_name)
  training_set = training_set.iloc[:,3:4].values

  plt.rcParams['figure.figsize'] = [15, 3]
  plt.rcParams['figure.dpi'] = 100

  plt.plot(
    training_set,
    label='Real Data'
  )

  """## Dataloading"""

  def sliding_windows(data, seq_length, pred_length):
      x = []
      y = []

      for i in range(len(data) - seq_length - 1 - pred_length):
          _x = data[i : (i + seq_length)]
          _y = data[i + seq_length : (i + seq_length + pred_length)]

          x.append(_x)
          y.append(_y.flatten())

      return np.array(x),np.array(y)

  sc = MinMaxScaler()
  training_data = sc.fit_transform(training_set)

  seq_length = 5
  pred_length = 15
  x, y = sliding_windows(training_data, seq_length, pred_length)

  train_size = int(len(y) * 0.67)
  test_size = len(y) - train_size

  dataX = Variable(torch.Tensor(np.array(x)))
  dataY = Variable(torch.Tensor(np.array(y)))

  trainX = Variable(torch.Tensor(np.array(x[0:train_size])))
  trainY = Variable(torch.Tensor(np.array(y[0:train_size])))

  testX = Variable(torch.Tensor(np.array(x[train_size:len(x)])))
  testY = Variable(torch.Tensor(np.array(y[train_size:len(y)])))

  """## Model"""

  class LSTM(nn.Module):

      def __init__(self, num_classes, input_size, hidden_size, num_layers):
          super(LSTM, self).__init__()

          self.num_classes = num_classes
          self.num_layers = num_layers
          self.input_size = input_size
          self.hidden_size = hidden_size
          self.seq_length = seq_length

          self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size,
                              num_layers=num_layers, batch_first=True)

          self.fc = nn.Linear(hidden_size, num_classes)

      def forward(self, x):
          h_0 = Variable(torch.zeros(
              self.num_layers, x.size(0), self.hidden_size))

          c_0 = Variable(torch.zeros(
              self.num_layers, x.size(0), self.hidden_size))

          # Propagate input through LSTM
          ula, (h_out, _) = self.lstm(x, (h_0, c_0))

          h_out = h_out.view(-1, self.hidden_size)

          out = self.fc(h_out)

          return out

  """## Training"""

  num_epochs = 500
  learning_rate = 0.01

  input_size = 1
  hidden_size = 2
  num_layers = 1

  num_classes = pred_length

  lstm = LSTM(num_classes, input_size, hidden_size, num_layers)

  criterion = torch.nn.MSELoss()    # mean-squared error for regression
  optimizer = torch.optim.Adam(lstm.parameters(), lr=learning_rate)

  train_losses = []
  test_losses = []

  # Train the model
  for epoch in range(num_epochs):
      outputs = lstm(trainX)
      optimizer.zero_grad()

      with torch.no_grad():
        y_test_pred = lstm(testX)
        test_loss = criterion(y_test_pred, testY)
      test_losses.append(test_loss.item())

      # obtain the loss function
      loss = criterion(outputs, trainY)

      loss.backward()

      train_losses.append(loss.item())

      optimizer.step()
      if epoch % 10 == 0:
        print(f"[Epoch {epoch}] train loss: {round(loss.item(), 4)}, test loss: {round(test_loss.item(), 4)}")

  plt.plot(
    train_losses,
    label='Train'
  )
  plt.plot(
    test_losses,
    label='Test'
  )
  plt.legend()

  """## Random Testing Plot"""

  idx = np.random.randint(len(testX))

  real_data = np.concatenate((
    testX[idx].data.numpy().flatten(),
    testY[idx].data.numpy().flatten()
  ))

  lstm.eval()
  pred_data = lstm(torch.unsqueeze(testX[idx], 0))
  pred_data = np.concatenate((
    real_data[:seq_length],
    pred_data.data.numpy().flatten()
  ))

  real_data = sc.inverse_transform(np.expand_dims(
    real_data,
    axis=0
  )).flatten()
  pred_data = sc.inverse_transform(np.expand_dims(
    pred_data,
    axis=0
  )).flatten()

  plt.axvline(x=seq_length-0.5, c='r', linestyle='--')
  plt.plot(
    pred_data,
    label = 'Predict',
    c='r',
    marker='o'
  )
  plt.plot(
    real_data,
    label = 'Real',
    c='b',
    marker='o'
  )
  plt.legend()

  """## Prediction of  2022/03/30 ~ 2022/04/13 (15 days)"""

  real_data = sc.fit_transform(np.array(training_set[-seq_length:]))
  real_data = Variable(torch.Tensor(real_data))
  real_data = torch.unsqueeze(real_data, 0)

  lstm.eval()
  pred_data = lstm(real_data)
  pred_data = sc.inverse_transform(np.expand_dims(
    torch.squeeze(pred_data, 0).data.numpy(),
    axis=0
  )).flatten()

  plt_data = np.concatenate((
    training_set[-seq_length:].flatten(),
    pred_data
  ))
  plt.plot(
    plt_data,
    marker='o'
  )
  plt.axvline(x=seq_length-0.5, c='r', linestyle='--')

  print('Model input:', training_set[-seq_length:].flatten())
  print('Model output:', pred_data)

  """## Save prediction to .csv"""

  pred_dates = [
    20220330, 20220331, 20220401, 20220402, 20220403,
    20220404, 20220405, 20220406, 20220407, 20220408,
    20220409, 20220410, 20220411, 20220412, 20220413
  ]
  dict = {'date': pred_dates, 'operating_reserve(MW)': pred_data}
  df = pd.DataFrame(dict)
  df.to_csv(output_file_name)
  df.head(15)

if __name__ == '__main__':
    # You should not modify this part, but additional arguments are allowed.
    import argparse

    parser = argparse.ArgumentParser()
    parser.add_argument('--training',
                       default='training_data.csv',
                       help='input training data file name')

    parser.add_argument('--output',
                        default='submission.csv',
                        help='output file name')
    args = parser.parse_args()

    # The following part is an example.
    # You can modify it at will.
    print(args.training, args.output)
    train_and_predict(args.training, args.output)
